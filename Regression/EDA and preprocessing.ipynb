{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from the problem statement figure out the type of learning it belongs to the reason is for the supervised learning we need to identify the input and output columns\n",
    "# Rule that the dataset should follow\n",
    "### 1. Feed only needed features\n",
    "### 2. No missing values\n",
    "### 3. There should not be any categorical values or string values\n",
    "### 4. All the values should be on the same scale\n",
    "### 5. Split your x and y into training and test set in case of supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv('D:/BJG Study Material/Resource Person/2020-21/rait/How Real Time Predictions are done with Machine Learning/programs/datasets/Data_preprocessing.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      "Country      10 non-null object\n",
      "Age          9 non-null float64\n",
      "Salary       9 non-null float64\n",
      "Purchased    10 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 280.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      0\n",
       "Age          1\n",
       "Salary       1\n",
       "Purchased    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.77777777777778\n"
     ]
    }
   ],
   "source": [
    "print(df['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# extracting x and y from the dataset\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 61000.0]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.0 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# imputing the missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "x[:,1:3] = imputer.fit_transform(x[:,1:3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 61000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.0 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# encoding the categorical values\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],\n",
    "                       remainder='passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# encoding y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22474487 -0.65465367 -0.65465367  0.76973439  0.77256767]\n",
      " [-0.81649658 -0.65465367  1.52752523 -1.69922498 -1.40879986]\n",
      " [-0.81649658  1.52752523 -0.65465367 -1.26352627 -0.86345798]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.10166303 -0.22722578]\n",
      " [-0.81649658  1.52752523 -0.65465367  0.18880278 -0.22722578]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.53736175 -0.49989673]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.10166303 -1.04523861]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  1.35066601  1.40879986]\n",
      " [-0.81649658  1.52752523 -0.65465367  1.64113182  1.77236112]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.24689594  0.3181161 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22474487 -0.65465367 -0.65465367 -0.24689594  0.3181161 ]\n",
      " [-0.81649658 -0.65465367  1.52752523 -1.69922498 -1.40879986]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.10166303 -1.04523861]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  1.35066601  1.40879986]\n",
      " [-0.81649658 -0.65465367  1.52752523 -0.10166303 -0.22722578]\n",
      " [ 1.22474487 -0.65465367 -0.65465367  0.76973439  0.77256767]\n",
      " [ 1.22474487 -0.65465367 -0.65465367 -0.53736175 -0.49989673]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# the train test split function split x and y into training and test set\n",
    "# by random shuffle pf the rows. to keep this random shuffle constant for all of\n",
    "# us we use the random state parametere\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,\n",
    "                                                random_state=0)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
